{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "e4l4MNwqBNYt"
      ],
      "mount_file_id": "1X8PfmED3dfL72WQjQn4OyRJUOCDJNSZy",
      "authorship_tag": "ABX9TyPEH3L2jXbxj0D2Ud8nAN44",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cruz-marco/pyspark_course/blob/main/pyspark_DataFrame.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação e configuração Spark"
      ],
      "metadata": {
        "id": "e4l4MNwqBNYt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lPKFS4-M_m3v"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.3/spark-3.2.3-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.3-bin-hadoop3.2.tgz\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" \n",
        "os.environ[\"SPARK_HOME\"] = '/content/spark-3.2.3-bin-hadoop3.2'\n",
        "\n",
        "!pip install -q findspark\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataFrames\n",
        "\n",
        "- Tabelas com linhas e colunas;\n",
        "- Imutáveis;\n",
        "- Schema conhecido;\n",
        "- Linhagem Preservada;\n",
        "- Colunas podem ter tipos diferentes;\n",
        "- Podemos agrupar, ordenar e filtrar;\n",
        "- Spark otimiza análises usando planos de execução (DAG's)\n",
        "\n",
        "## Lazy Evaluation\n",
        "> O processamento da transformação só ocorre quando há uma ação: \n",
        "\n",
        "## Ações:\n",
        "> (reduce, collect, count, first, take, takeSample, takeOrdered, saveAsTestFile, saveAsSequenceFile, saveAsObjectFile, countByKey, foreach)\n",
        "\n",
        "## Transformações:\n",
        "> (map, filter, flatMap, mapPartitions, mapPartitionsWithIndex, sample, union, intersection, distinct, groupByKey, reduceByKey, aggregateByKey, sortByKey, join, cogroup, cartesian, pipe, coalesce, repartition, repartitionAndSortWithinPartitions)\n"
      ],
      "metadata": {
        "id": "NfYXPqPABlN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando um [DataFrame](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.html#pyspark.sql.DataFrame) de exemplo:\n",
        "- [spark.createDataFrame()](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.SparkSession.createDataFrame.html)"
      ],
      "metadata": {
        "id": "6Fl7TU3g0En0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Pedro\", 10), (\"Maria\", 20), (\"José\", 40)] #Dados a serem inseridos na tabela\n",
        "df1 = spark.createDataFrame(data) #instanciando o DataFrame\n",
        "df1.show() #Comando para mostar o frame, pode recer um parâmetro com o número."
      ],
      "metadata": {
        "id": "KHayJtLSBkNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a6a319-e7b2-4e6e-a8dd-3f3e448fd130"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "|   _1| _2|\n",
            "+-----+---+\n",
            "|Pedro| 10|\n",
            "|Maria| 20|\n",
            "| José| 40|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema = \"Id INT, Nome STRING\" #definindo um schema a ser usado no DataFrame\n",
        "data_2 = [(1, \"Pedro\"), (2, \"Maria\")]\n",
        "\n",
        "df2 = spark.createDataFrame(data_2, schema=schema)\n",
        "\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSxHM0wLyCHS",
        "outputId": "258542d2-2ca5-4559-d74b-2cb67ef8b3dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| Id| Nome|\n",
            "+---+-----+\n",
            "|  1|Pedro|\n",
            "|  2|Maria|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pacote de [funções](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html):"
      ],
      "metadata": {
        "id": "iFTQ5U6n2vlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as f #Importando a biblioteca de funções\n",
        "schema_2 = \"produtos STRING, vendas INT\"\n",
        "vendas = [(\"Caneta\", 10), (\"Lápis\", 20), (\"Caneta\", 40)]\n",
        "\n",
        "df3 = spark.createDataFrame(vendas, schema_2)\n",
        "\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGEHfXFW1ari",
        "outputId": "8e7650cd-c55f-43a5-bb9f-eb55279d3bd4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+\n",
            "|produtos|vendas|\n",
            "+--------+------+\n",
            "|  Caneta|    10|\n",
            "|   Lápis|    20|\n",
            "|  Caneta|    40|\n",
            "+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Diferente do Pandas, as funções ficam em um pacote a parte, \n",
        "logo, temos que fazer o import ou do pacote, ou da função \n",
        "específica. Por exemplo, a sum() utilizada com o método de \n",
        "agregação, conforme mostrado abaixo.\n",
        "\"\"\"\n",
        "\n",
        "agrupado = df3.groupBy(\"produtos\")\\\n",
        "            .agg(f.sum(\"vendas\"))\n",
        "\n",
        "agrupado.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcX8pjOm2Ki8",
        "outputId": "eaf9b1a0-bec8-4e9a-b5ed-44de4e8b691f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+\n",
            "|produtos|sum(vendas)|\n",
            "+--------+-----------+\n",
            "|  Caneta|         50|\n",
            "|   Lápis|         20|\n",
            "+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.select(\"produtos\").show() # Selecionando uma única coluna no DataFrame, por exemplo."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeUhhH5e2hos",
        "outputId": "f0b98c16-3b43-4f6c-d90b-60a42575f556"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|produtos|\n",
            "+--------+\n",
            "|  Caneta|\n",
            "|   Lápis|\n",
            "|  Caneta|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.select(\"produtos\", \"vendas\", f.expr(\"vendas * 0.2\")).show() \n",
        "\"\"\"\n",
        "A Função EXPR cria uma expressão que pode ser usada para criar mais uma linha\n",
        "no dataframe, enriquecendo a nossa análise. Ela recebe uma string com a\n",
        "expressão a ser processada.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "O04dJePN3Z5E",
        "outputId": "cb9faad8-bf46-4c50-baac-055b56fd8d02"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------------+\n",
            "|produtos|vendas|(vendas * 0.2)|\n",
            "+--------+------+--------------+\n",
            "|  Caneta|    10|           2.0|\n",
            "|   Lápis|    20|           4.0|\n",
            "|  Caneta|    40|           8.0|\n",
            "+--------+------+--------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nA Função EXPR cria uma expressão que pode ser usada para criar mais uma linha\\nno dataframe, enriquecendo a nossa análise. Ela recebe uma string com a\\nexpressão a ser processada.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(\n",
        "    df3.schema, # ver a estrutura das colunas\n",
        "    df3.columns # ver os nomes das colunas\n",
        ")"
      ],
      "metadata": {
        "id": "Kj-y3RuZ41mW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "70ccfa6c-da32-4738-f054-e915f9420490"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "StructType(List(StructField(produtos,StringType,true),StructField(vendas,IntegerType,true)))"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['produtos', 'vendas']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando dados de duas maneiras distintas no Spark (DataFrames)"
      ],
      "metadata": {
        "id": "b6zJZUVCtQqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando o spark.read.csv:"
      ],
      "metadata": {
        "id": "xsE-IJuStaNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "arqschema = \"id INT, nome STRING, status STRING, cidade STRING, vendas INT, data STRING\"\n",
        "# esquema de colunas, colocando seu nome e tipo, em sequência, para ser usado\n",
        "# como referência na leitura dos dados em CSV, para podermos escolher\n",
        "# os tipos de dados e o nome das colunas, visto que o CSV em questão não possui\n",
        "# cabeçalho.\n",
        "\n",
        "despachantes = spark.read.csv(\"/content/drive/MyDrive/Datasets/pyspark_course/despachantes.csv\", \n",
        "                              header=False, schema=arqschema)\n"
      ],
      "metadata": {
        "id": "6ppETgnpN1hS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "despachantes.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9TY1ZCVb1jm",
        "outputId": "4cf5dd20-92c7-4ebb-9fcc-e39f4cc6d8d0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+------+-------------+------+----------+\n",
            "| id|               nome|status|       cidade|vendas|      data|\n",
            "+---+-------------------+------+-------------+------+----------+\n",
            "|  1|   Carminda Pestana| Ativo|  Santa Maria|    23|2020-08-11|\n",
            "|  2|    Deolinda Vilela| Ativo|Novo Hamburgo|    34|2020-03-05|\n",
            "|  3|   Emídio Dornelles| Ativo| Porto Alegre|    34|2020-02-05|\n",
            "|  4|Felisbela Dornelles| Ativo| Porto Alegre|    36|2020-02-05|\n",
            "|  5|     Graça Ornellas| Ativo| Porto Alegre|    12|2020-02-05|\n",
            "|  6|   Matilde Rebouças| Ativo| Porto Alegre|    22|2019-01-05|\n",
            "|  7|    Noêmia   Orriça| Ativo|  Santa Maria|    45|2019-10-05|\n",
            "|  8|      Roque Vásquez| Ativo| Porto Alegre|    65|2020-03-05|\n",
            "|  9|      Uriel Queiroz| Ativo| Porto Alegre|    54|2018-05-05|\n",
            "| 10|   Viviana Sequeira| Ativo| Porto Alegre|     0|2020-09-05|\n",
            "+---+-------------------+------+-------------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "despachantes.groupBy(\"cidade\")\\\n",
        ".agg(f.sum(\"vendas\")).show()\n",
        "# Exemplo de groupBy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENJ2HAvYb7WM",
        "outputId": "7aa8a46a-ddcd-4dc8-feb8-f8b5dd025785"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----------+\n",
            "|       cidade|sum(vendas)|\n",
            "+-------------+-----------+\n",
            "|  Santa Maria|         68|\n",
            "|Novo Hamburgo|         34|\n",
            "| Porto Alegre|        223|\n",
            "+-------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando o spark.read.load:"
      ],
      "metadata": {
        "id": "LAwMwgc_u7lJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "desp_autoschema = spark.read.load(\"/content/drive/MyDrive/Datasets/pyspark_course/despachantes.csv\",\n",
        "                                  header=False, format=\"csv\", sep=\",\",\n",
        "                                  inferSchema=True)\n",
        "# forma um tanto mais sucinta, é necessário informar o formato e permitir o \n",
        "# parâmetro inferSchema (valor True) para que o próprio spark deduza o tipo\n",
        "# de dados sozinho. É uma boa prática informar qual o tipo de separador SEP,\n",
        "# pois no Brasil, usamos a vírgula para declarar a parte decimal de um número\n",
        "# não inteiro."
      ],
      "metadata": {
        "id": "eFFlm09ZcPIY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desp_autoschema.show()\n",
        "# como o arquivo não tem cabeçalho, o spark nomeia as colunas automaticamente."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjCUntkRczTh",
        "outputId": "2d2367f6-b328-4eab-bd17-57c80b35cd5d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+-----+-------------+---+----------+\n",
            "|_c0|                _c1|  _c2|          _c3|_c4|       _c5|\n",
            "+---+-------------------+-----+-------------+---+----------+\n",
            "|  1|   Carminda Pestana|Ativo|  Santa Maria| 23|2020-08-11|\n",
            "|  2|    Deolinda Vilela|Ativo|Novo Hamburgo| 34|2020-03-05|\n",
            "|  3|   Emídio Dornelles|Ativo| Porto Alegre| 34|2020-02-05|\n",
            "|  4|Felisbela Dornelles|Ativo| Porto Alegre| 36|2020-02-05|\n",
            "|  5|     Graça Ornellas|Ativo| Porto Alegre| 12|2020-02-05|\n",
            "|  6|   Matilde Rebouças|Ativo| Porto Alegre| 22|2019-01-05|\n",
            "|  7|    Noêmia   Orriça|Ativo|  Santa Maria| 45|2019-10-05|\n",
            "|  8|      Roque Vásquez|Ativo| Porto Alegre| 65|2020-03-05|\n",
            "|  9|      Uriel Queiroz|Ativo| Porto Alegre| 54|2018-05-05|\n",
            "| 10|   Viviana Sequeira|Ativo| Porto Alegre|  0|2020-09-05|\n",
            "+---+-------------------+-----+-------------+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(\n",
        "    despachantes.schema, # comparação dos schemas declarados e inferidos.\n",
        "    \"------------------\",\n",
        "    desp_autoschema.schema\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "D0NLwA_Sc2wh",
        "outputId": "60a5b6d7-a978-485a-9e25-3529736b2922"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "StructType(List(StructField(id,IntegerType,true),StructField(nome,StringType,true),StructField(status,StringType,true),StructField(cidade,StringType,true),StructField(vendas,IntegerType,true),StructField(data,StringType,true)))"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'------------------'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "StructType(List(StructField(_c0,IntegerType,true),StructField(_c1,StringType,true),StructField(_c2,StringType,true),StructField(_c3,StringType,true),StructField(_c4,IntegerType,true),StructField(_c5,StringType,true)))"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fazendo consultas\n",
        "\n",
        "> Select, Where, OrderBy, Distinct são cláusulas SQL que no PySpark são métodos do objeto DataFrame, diferentemente do pandas, temos que usar o SELECT para selecionar as colunas que nos interessam, no lugar de exibirmos todas."
      ],
      "metadata": {
        "id": "pwcKnFLnv7P0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "despachantes.select(\"id\", \"nome\", \"vendas\")\\\n",
        "        .where(f.col(\"vendas\") > 20)\\\n",
        "        .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVdYdfh0dR1i",
        "outputId": "444632be-3a2e-455e-d843-73650569201c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+------+\n",
            "| id|               nome|vendas|\n",
            "+---+-------------------+------+\n",
            "|  1|   Carminda Pestana|    23|\n",
            "|  2|    Deolinda Vilela|    34|\n",
            "|  3|   Emídio Dornelles|    34|\n",
            "|  4|Felisbela Dornelles|    36|\n",
            "|  6|   Matilde Rebouças|    22|\n",
            "|  7|    Noêmia   Orriça|    45|\n",
            "|  8|      Roque Vásquez|    65|\n",
            "|  9|      Uriel Queiroz|    54|\n",
            "+---+-------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> A cláusula WHERE deve ser usada juntamente com a função COL do pacote de funções SQL do PySpark. As condições podem ser conectadas usando \"&\" e \"|\", e uma expressão pode ser negada usando \"~\"."
      ],
      "metadata": {
        "id": "RPiSPaUGwdVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "despachantes.select(\"id\", \"nome\", \"vendas\")\\\n",
        "        .where((f.col(\"vendas\") > 20) & (f.col(\"vendas\") < 40))\\\n",
        "        .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gu_t-qWfKIF",
        "outputId": "75b5c52a-1527-4e9e-96af-3b544b44ac05"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+------+\n",
            "| id|               nome|vendas|\n",
            "+---+-------------------+------+\n",
            "|  1|   Carminda Pestana|    23|\n",
            "|  2|    Deolinda Vilela|    34|\n",
            "|  3|   Emídio Dornelles|    34|\n",
            "|  4|Felisbela Dornelles|    36|\n",
            "|  6|   Matilde Rebouças|    22|\n",
            "+---+-------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Renomeando colunas:\n",
        "> Diferente do pandas, onde podemos renomear diversas colunas passando um dicionário como parâmetro para o método da classe DataFrame; as colunas do DataFrame do PySpark devem ser renomeadas uma a uma. Portanto, faz-se necessário o uso de um loop, caso queiramos renomear mais de uma de forma ágil, por exemplo."
      ],
      "metadata": {
        "id": "C4QAu-GGxG-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#renomeando todas as colunas de uma só vez numa nova variável\n",
        "# novo_desp\n",
        "novo_desp = desp_autoschema\n",
        "for i in list(zip(desp_autoschema.columns, despachantes.columns)):\n",
        "  novo_desp = novo_desp.withColumnRenamed(*i)\n",
        "\n",
        "novo_desp.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFVfoxvifjug",
        "outputId": "f8172546-2884-40e5-c74a-d342b8a2b5a0"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+------+-------------+------+----------+\n",
            "| id|               nome|status|       cidade|vendas|      data|\n",
            "+---+-------------------+------+-------------+------+----------+\n",
            "|  1|   Carminda Pestana| Ativo|  Santa Maria|    23|2020-08-11|\n",
            "|  2|    Deolinda Vilela| Ativo|Novo Hamburgo|    34|2020-03-05|\n",
            "|  3|   Emídio Dornelles| Ativo| Porto Alegre|    34|2020-02-05|\n",
            "|  4|Felisbela Dornelles| Ativo| Porto Alegre|    36|2020-02-05|\n",
            "|  5|     Graça Ornellas| Ativo| Porto Alegre|    12|2020-02-05|\n",
            "|  6|   Matilde Rebouças| Ativo| Porto Alegre|    22|2019-01-05|\n",
            "|  7|    Noêmia   Orriça| Ativo|  Santa Maria|    45|2019-10-05|\n",
            "|  8|      Roque Vásquez| Ativo| Porto Alegre|    65|2020-03-05|\n",
            "|  9|      Uriel Queiroz| Ativo| Porto Alegre|    54|2018-05-05|\n",
            "| 10|   Viviana Sequeira| Ativo| Porto Alegre|     0|2020-09-05|\n",
            "+---+-------------------+------+-------------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando uma nova coluna com os dados da coluna data com o tipo timestamp"
      ],
      "metadata": {
        "id": "CU7Q7W3rzw3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novo_desp = novo_desp.withColumn(\"data2\", f.to_timestamp(f.col(\"data\"), \n",
        "                                \"yyyy-MM-dd\"))\n",
        "novo_desp.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6RyQMGxnu_R",
        "outputId": "de5645da-af07-421c-8659-5f97582f6a8a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+------+-------------+------+----------+-------------------+\n",
            "| id|               nome|status|       cidade|vendas|      data|              data2|\n",
            "+---+-------------------+------+-------------+------+----------+-------------------+\n",
            "|  1|   Carminda Pestana| Ativo|  Santa Maria|    23|2020-08-11|2020-08-11 00:00:00|\n",
            "|  2|    Deolinda Vilela| Ativo|Novo Hamburgo|    34|2020-03-05|2020-03-05 00:00:00|\n",
            "|  3|   Emídio Dornelles| Ativo| Porto Alegre|    34|2020-02-05|2020-02-05 00:00:00|\n",
            "|  4|Felisbela Dornelles| Ativo| Porto Alegre|    36|2020-02-05|2020-02-05 00:00:00|\n",
            "|  5|     Graça Ornellas| Ativo| Porto Alegre|    12|2020-02-05|2020-02-05 00:00:00|\n",
            "|  6|   Matilde Rebouças| Ativo| Porto Alegre|    22|2019-01-05|2019-01-05 00:00:00|\n",
            "|  7|    Noêmia   Orriça| Ativo|  Santa Maria|    45|2019-10-05|2019-10-05 00:00:00|\n",
            "|  8|      Roque Vásquez| Ativo| Porto Alegre|    65|2020-03-05|2020-03-05 00:00:00|\n",
            "|  9|      Uriel Queiroz| Ativo| Porto Alegre|    54|2018-05-05|2018-05-05 00:00:00|\n",
            "| 10|   Viviana Sequeira| Ativo| Porto Alegre|     0|2020-09-05|2020-09-05 00:00:00|\n",
            "+---+-------------------+------+-------------+------+----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "novo_desp.schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYA8nTgFo5Fy",
        "outputId": "f357600d-4c20-4c41-d5c9-b0d9d012c78d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType(List(StructField(id,IntegerType,true),StructField(nome,StringType,true),StructField(status,StringType,true),StructField(cidade,StringType,true),StructField(vendas,IntegerType,true),StructField(data,StringType,true),StructField(data2,TimestampType,true)))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Selecionando os anos das datas (str e timestamp) e os nomes dos despachantes, ordenando por nome."
      ],
      "metadata": {
        "id": "2AJ5qLqF0DVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novo_desp.select(f.year(\"data\"), f.year(\"data2\"), \"nome\")\\\n",
        "                .distinct()\\\n",
        "                .orderBy(\"nome\")\\\n",
        "                .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTaA_mcMpBTq",
        "outputId": "2bf0716d-3fa9-460b-8645-c07c8b1466b1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+-------------------+\n",
            "|year(data)|year(data2)|               nome|\n",
            "+----------+-----------+-------------------+\n",
            "|      2020|       2020|   Carminda Pestana|\n",
            "|      2020|       2020|    Deolinda Vilela|\n",
            "|      2020|       2020|   Emídio Dornelles|\n",
            "|      2020|       2020|Felisbela Dornelles|\n",
            "|      2020|       2020|     Graça Ornellas|\n",
            "|      2019|       2019|   Matilde Rebouças|\n",
            "|      2019|       2019|    Noêmia   Orriça|\n",
            "|      2020|       2020|      Roque Vásquez|\n",
            "|      2018|       2018|      Uriel Queiroz|\n",
            "|      2020|       2020|   Viviana Sequeira|\n",
            "+----------+-----------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Usando o ALIAS, podemos dar apelidos para todas as colunas, logo, podemos criar um agrupamento usando as funções do pacote functions e as apelidando e usando a referência do apelido em outros métodos do DataFrame como o groupBy e o orderBy."
      ],
      "metadata": {
        "id": "nqkajluI0qLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novo_desp.select(f.year(\"data\").alias(\"anos\"))\\\n",
        "                .groupBy(\"anos\")\\\n",
        "                .agg(f.count(f.col(\"anos\")).alias(\"ocorr\"))\\\n",
        "                .orderBy(f.col(\"ocorr\").desc())\\\n",
        "                .show()#Só funciona se dermos um apelido para a coluna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5t7Dyl0psIN",
        "outputId": "2273545f-a4ba-4955-a987-1bd807387a7d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|anos|ocorr|\n",
            "+----+-----+\n",
            "|2020|    7|\n",
            "|2019|    2|\n",
            "|2018|    1|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Total de vendas"
      ],
      "metadata": {
        "id": "5giH2hGa0nYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novo_desp.select(f.sum(\"vendas\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqgeqXFAqBSB",
        "outputId": "a9b7e324-cbff-4d64-c85a-eaaacb45b889"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|sum(vendas)|\n",
            "+-----------+\n",
            "|        325|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Jgk8-nWtLPe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}