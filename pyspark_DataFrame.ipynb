{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "e4l4MNwqBNYt"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM0BXDebRyx3KDez3YptJYt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cruz-marco/pyspark_course/blob/main/pyspark_DataFrame.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação e configuração Spark"
      ],
      "metadata": {
        "id": "e4l4MNwqBNYt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lPKFS4-M_m3v"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.3/spark-3.2.3-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.3-bin-hadoop3.2.tgz\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" \n",
        "os.environ[\"SPARK_HOME\"] = '/content/spark-3.2.3-bin-hadoop3.2'\n",
        "\n",
        "!pip install -q findspark\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataFrames\n",
        "\n",
        "- Tabelas com linhas e colunas;\n",
        "- Imutáveis;\n",
        "- Schema conhecido;\n",
        "- Linhagem Preservada;\n",
        "- Colunas podem ter tipos diferentes;\n",
        "- Podemos agrupar, ordenar e filtrar;\n",
        "- Spark otimiza análises usando planos de execução (DAG's)\n",
        "\n",
        "## Lazy Evaluation\n",
        "> O processamento da transformação só ocorre quando há uma ação: \n",
        "\n",
        "## Ações:\n",
        "> (reduce, collect, count, first, take, takeSample, takeOrdered, saveAsTestFile, saveAsSequenceFile, saveAsObjectFile, countByKey, foreach)\n",
        "\n",
        "## Transformações:\n",
        "> (map, filter, flatMap, mapPartitions, mapPartitionsWithIndex, sample, union, intersection, distinct, groupByKey, reduceByKey, aggregateByKey, sortByKey, join, cogroup, cartesian, pipe, coalesce, repartition, repartitionAndSortWithinPartitions)\n"
      ],
      "metadata": {
        "id": "NfYXPqPABlN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando um [DataFrame](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.html#pyspark.sql.DataFrame) de exemplo:\n",
        "- [spark.createDataFrame()](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.SparkSession.createDataFrame.html)"
      ],
      "metadata": {
        "id": "6Fl7TU3g0En0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Pedro\", 10), (\"Maria\", 20), (\"José\", 40)] #Dados a serem inseridos na tabela\n",
        "df1 = spark.createDataFrame(data) #instanciando o DataFrame\n",
        "df1.show() #Comando para mostar o frame, pode recer um parâmetro com o número."
      ],
      "metadata": {
        "id": "KHayJtLSBkNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76cf722a-5bbc-4445-d9c2-b4659240bbde"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "|   _1| _2|\n",
            "+-----+---+\n",
            "|Pedro| 10|\n",
            "|Maria| 20|\n",
            "| José| 40|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema = \"Id INT, Nome STRING\" #definindo um schema a ser usado no DataFrame\n",
        "data_2 = [(1, \"Pedro\"), (2, \"Maria\")]\n",
        "\n",
        "df2 = spark.createDataFrame(data_2, schema=schema)\n",
        "\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSxHM0wLyCHS",
        "outputId": "33f5ca9d-69eb-4e66-b0e4-a0507b444262"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| Id| Nome|\n",
            "+---+-----+\n",
            "|  1|Pedro|\n",
            "|  2|Maria|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pacote de [funções](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html):"
      ],
      "metadata": {
        "id": "iFTQ5U6n2vlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum, expr #Importando a função SUM e EXPR\n",
        "schema_2 = \"produtos STRING, vendas INT\"\n",
        "vendas = [(\"Caneta\", 10), (\"Lápis\", 20), (\"Caneta\", 40)]\n",
        "\n",
        "df3 = spark.createDataFrame(vendas, schema_2)\n",
        "\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGEHfXFW1ari",
        "outputId": "7a9e9d2f-1094-4969-d1a8-d9e28d0af2aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+\n",
            "|produtos|vendas|\n",
            "+--------+------+\n",
            "|  Caneta|    10|\n",
            "|   Lápis|    20|\n",
            "|  Caneta|    40|\n",
            "+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Diferente do Pandas, as funções ficam em um pacote a parte, \n",
        "logo, temos que fazer o import ou do pacote, ou da função \n",
        "específica. Por exemplo, a sum() utilizada com o método de \n",
        "agregação, conforme mostrado abaixo.\n",
        "\"\"\"\n",
        "\n",
        "agrupado = df3.groupBy(\"produtos\")\\\n",
        "            .agg(sum(\"vendas\"))\n",
        "\n",
        "agrupado.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcX8pjOm2Ki8",
        "outputId": "5811a3b0-c3cc-43c5-d793-6893576c7302"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+\n",
            "|produtos|sum(vendas)|\n",
            "+--------+-----------+\n",
            "|  Caneta|         50|\n",
            "|   Lápis|         20|\n",
            "+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.select(\"produtos\").show() # Selecionando uma única coluna no DataFrame, por exemplo."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeUhhH5e2hos",
        "outputId": "87fd8ddd-af3e-49c0-cfab-72c08c362c94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|produtos|\n",
            "+--------+\n",
            "|  Caneta|\n",
            "|   Lápis|\n",
            "|  Caneta|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.select(\"produtos\", \"vendas\", expr(\"vendas * 0.2\")).show() \n",
        "\"\"\"\n",
        "A Função EXPR cria uma expressão que pode ser usada para criar mais uma linha\n",
        "no dataframe, enriquecendo a nossa análise. Ela recebe uma string com a\n",
        "expressão a ser processada.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "O04dJePN3Z5E",
        "outputId": "b141ec31-30b6-4c36-a548-ce7e504a3bab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------------+\n",
            "|produtos|vendas|(vendas * 0.2)|\n",
            "+--------+------+--------------+\n",
            "|  Caneta|    10|           2.0|\n",
            "|   Lápis|    20|           4.0|\n",
            "|  Caneta|    40|           8.0|\n",
            "+--------+------+--------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nA Função EXPR cria uma expressão que pode ser usada para criar mais uma linha\\nno dataframe, enriquecendo a nossa análise. Ela recebe uma string com a\\nexpressão a ser processada.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kj-y3RuZ41mW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}