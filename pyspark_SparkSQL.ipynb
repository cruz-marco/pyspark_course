{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1uZiSS_kkL9MEa3IY1XCfCuW1vxw_YQDD",
      "authorship_tag": "ABX9TyOi7eyWY+EiCUn5tymXKzK1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cruz-marco/pyspark_course/blob/main/pyspark_SparkSQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "qfHMMFM-LpIZ"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.3/spark-3.2.3-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.3-bin-hadoop3.2.tgz\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" \n",
        "os.environ[\"SPARK_HOME\"] = '/content/spark-3.2.3-bin-hadoop3.2'\n",
        "\n",
        "!pip install -q findspark\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark SQL\n",
        "\n",
        "- O Spark permite també utilizar tabelas dentro de banco de dados um ambiente que se assemelha ao de um banco de dados relacional comum (Postgres, MySQL)\n",
        "\n",
        "- As tabelas são exatamente iguais em estrutura e funcionalidades aos bancos de dado SQL. Diferindo dos DataFrames, as tabelas são objetos que persistem depois que a sessão do Spark é finalizada.\n",
        "\n",
        "- Tabelas e DataFrames são totalmente interoperáveis no ambiente Spark, logo, podemos fazer o cast de um tipo de estrutura para outro sem muito problema.\n",
        "\n",
        "- Apesar de sermos completamente livres para fazer consultas e gerenciamento de bancos de dados e tabelas pelo spark, o retorno no framework do PySpark é sempre em um objeto DataFrame, o que não significa que a tabela seja mutável, mas que a saída daquela consulta usa o tipo de dado DataFrame.\n",
        "\n",
        "## 1. Tipos de Tabelas:\n",
        "> **Gerenciadas (Managed)**: Spark gerendia os dados e os metadados deta tabela. Se apagarmos esta tabela, ela desaparece por completo (dados e metadados desaparecem). Ficam armazenadas no Warehouse do Spark.\n",
        "\n",
        "> **Não Gerenciadas (External)**: É uma tabelo onde apenas os metadados são gerenciados pelo Spark e os dados em si estão localizados um um ludar diferente do Spark Warehouse.\n",
        "\n",
        "## 2. Views:\n",
        "As views são apelidos que podemos dar a uma tabela que é criada a partir de uma consulta. Usando joins ou criando novas colunas com os dados, por exemplo. O uso de views facilita o trabalho quando precisamos executar uma consulta mais complexa e que necessita de um aninhamento de selects, por exemplo.\n",
        "### Podem ser de dois tipos:\n",
        "> **Globais**: Visíveis em todas as sessões.\n",
        "\n",
        "> **Sessão**: Visíveis apenas na sessão atual, sendo destruídas quando a mesma é encerrada.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n12k3ojLTE2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando o dataframe despachantes para ser usado nos exemplos a seguir."
      ],
      "metadata": {
        "id": "ASkO2z0aWxzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "arqschema = \"id INT, nome STRING, status STRING, cidade STRING, vendas INT, data STRING\"\n",
        "\n",
        "despachantes = spark.read.csv(\"/content/drive/MyDrive/Datasets/pyspark_course/despachantes.csv\", \n",
        "                              header=False, schema=arqschema)"
      ],
      "metadata": {
        "id": "Egn-CzhaLz-q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mostrando e criando os bancos de dados."
      ],
      "metadata": {
        "id": "O1VvAYibW62_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('show databases').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipkFnEN5PwZS",
        "outputId": "9dc5b171-51dd-44a7-f21c-987443e37593"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|namespace|\n",
            "+---------+\n",
            "|  default|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('create database desp').show() # Criando o banco de dados DESP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XecLutH0QUuI",
        "outputId": "177b1668-fae2-4546-b553-f0258d40fd9f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++\n",
            "||\n",
            "++\n",
            "++\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('show databases').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB8ayVYxQhtl",
        "outputId": "3111000d-e5aa-47b2-9adf-16ed707b9e82"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|namespace|\n",
            "+---------+\n",
            "|  default|\n",
            "|     desp|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('use desp') # Selecionando o banco de dados DESP para ser usado."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO5XEZMZQmQ9",
        "outputId": "4930b66d-2125-4e3d-a7c7-2e311dc476a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Com o banco de dados criado e selecionado, podemos escrever o DataFrame *despachantes* completo como uma tabela dentro do banco de dados DESP com apenas umalinha de código."
      ],
      "metadata": {
        "id": "WQVdYBbnXI6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "despachantes.write.saveAsTable(\"Despachantes\") "
      ],
      "metadata": {
        "id": "3b7uMySRQuMG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mostrando a recém criada **TABELA** Despachantes usando um select clássico SQL."
      ],
      "metadata": {
        "id": "Ww6yEnIvXbni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select * from Despachantes').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPdTWRx5RTpR",
        "outputId": "71d8ae4c-488b-4b3f-9dc2-513521b3e067"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+------+-------------+------+----------+\n",
            "| id|               nome|status|       cidade|vendas|      data|\n",
            "+---+-------------------+------+-------------+------+----------+\n",
            "|  1|   Carminda Pestana| Ativo|  Santa Maria|    23|2020-08-11|\n",
            "|  2|    Deolinda Vilela| Ativo|Novo Hamburgo|    34|2020-03-05|\n",
            "|  3|   Emídio Dornelles| Ativo| Porto Alegre|    34|2020-02-05|\n",
            "|  4|Felisbela Dornelles| Ativo| Porto Alegre|    36|2020-02-05|\n",
            "|  5|     Graça Ornellas| Ativo| Porto Alegre|    12|2020-02-05|\n",
            "|  6|   Matilde Rebouças| Ativo| Porto Alegre|    22|2019-01-05|\n",
            "|  7|    Noêmia   Orriça| Ativo|  Santa Maria|    45|2019-10-05|\n",
            "|  8|      Roque Vásquez| Ativo| Porto Alegre|    65|2020-03-05|\n",
            "|  9|      Uriel Queiroz| Ativo| Porto Alegre|    54|2018-05-05|\n",
            "| 10|   Viviana Sequeira| Ativo| Porto Alegre|     0|2020-09-05|\n",
            "+---+-------------------+------+-------------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mostrando as tabelas contidas no banco de dados Desp"
      ],
      "metadata": {
        "id": "KCqALQcMXrId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('show tables').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw5GgJUqRcet",
        "outputId": "e877b773-e6f9-497b-e2b5-3745bdf94f78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+-----------+\n",
            "|namespace|   tableName|isTemporary|\n",
            "+---------+------------+-----------+\n",
            "|     desp|despachantes|      false|\n",
            "+---------+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inserindo o método \"*.mode()*\" podemos modificar o modo de escrita da tabela. Por exemplo, usando OVERWRITE para sobrescrever ou APPEND para adicionar mais linhas mantendo as que já estão persistidas na tabela.."
      ],
      "metadata": {
        "id": "wwEojlXPXxGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "despachantes.write.mode('overwrite').saveAsTable(\"Despachantes\")"
      ],
      "metadata": {
        "id": "E5whO1GARibg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "despachantes_tb = spark.sql('select * from Despachantes')\n",
        "despachantes_tb.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBW0hRm9R6Zn",
        "outputId": "05e87459-6643-41fb-cd70-bbba96d6127c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+------+-------------+------+----------+\n",
            "| id|               nome|status|       cidade|vendas|      data|\n",
            "+---+-------------------+------+-------------+------+----------+\n",
            "|  1|   Carminda Pestana| Ativo|  Santa Maria|    23|2020-08-11|\n",
            "|  2|    Deolinda Vilela| Ativo|Novo Hamburgo|    34|2020-03-05|\n",
            "|  3|   Emídio Dornelles| Ativo| Porto Alegre|    34|2020-02-05|\n",
            "|  4|Felisbela Dornelles| Ativo| Porto Alegre|    36|2020-02-05|\n",
            "|  5|     Graça Ornellas| Ativo| Porto Alegre|    12|2020-02-05|\n",
            "|  6|   Matilde Rebouças| Ativo| Porto Alegre|    22|2019-01-05|\n",
            "|  7|    Noêmia   Orriça| Ativo|  Santa Maria|    45|2019-10-05|\n",
            "|  8|      Roque Vásquez| Ativo| Porto Alegre|    65|2020-03-05|\n",
            "|  9|      Uriel Queiroz| Ativo| Porto Alegre|    54|2018-05-05|\n",
            "| 10|   Viviana Sequeira| Ativo| Porto Alegre|     0|2020-09-05|\n",
            "+---+-------------------+------+-------------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tipos de Tabelas"
      ],
      "metadata": {
        "id": "XktCgxjVm8JA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Salvando um DataFrame como arquivo parquet"
      ],
      "metadata": {
        "id": "OzR0rtZInDbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "despachantes_tb.write.format(\"parquet\").save(\"/content/pyspark_course/dfpqt01\")"
      ],
      "metadata": {
        "id": "7_dJ6sseZyPs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Salvando o DataFrame como tabela na pasta descrita no método option() como não gerenciado ou EXTERNAL"
      ],
      "metadata": {
        "id": "n8faLHo0nLAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#spark.sql.legacy.allowNonEmptyLocationInCTAS = True\n",
        "despachantes_tb.write.option('path', '/content/pyspark_course/dfpqt02').saveAsTable('Despachantes_ng')"
      ],
      "metadata": {
        "id": "7cClBGkQcai6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('select * from Despachantes_ng').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YPAw_zJcxB2",
        "outputId": "9ff29139-0fcc-423a-ccd3-687e54c3d9f7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------------+------+-------------+------+----------+\n",
            "| id|               nome|status|       cidade|vendas|      data|\n",
            "+---+-------------------+------+-------------+------+----------+\n",
            "|  1|   Carminda Pestana| Ativo|  Santa Maria|    23|2020-08-11|\n",
            "|  2|    Deolinda Vilela| Ativo|Novo Hamburgo|    34|2020-03-05|\n",
            "|  3|   Emídio Dornelles| Ativo| Porto Alegre|    34|2020-02-05|\n",
            "|  4|Felisbela Dornelles| Ativo| Porto Alegre|    36|2020-02-05|\n",
            "|  5|     Graça Ornellas| Ativo| Porto Alegre|    12|2020-02-05|\n",
            "|  6|   Matilde Rebouças| Ativo| Porto Alegre|    22|2019-01-05|\n",
            "|  7|    Noêmia   Orriça| Ativo|  Santa Maria|    45|2019-10-05|\n",
            "|  8|      Roque Vásquez| Ativo| Porto Alegre|    65|2020-03-05|\n",
            "|  9|      Uriel Queiroz| Ativo| Porto Alegre|    54|2018-05-05|\n",
            "| 10|   Viviana Sequeira| Ativo| Porto Alegre|     0|2020-09-05|\n",
            "+---+-------------------+------+-------------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Despachantes é uma tabela gerenciada pois foi estruturada e populada devidamente dentro do banco de dados do Spark, logo, ele gerencia todo o conteúdo de dados e metadados da tabela."
      ],
      "metadata": {
        "id": "SWunrcHvndVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('show create table Despachantes').show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0pAOhyTdCG2",
        "outputId": "2687b338-4e0e-4118-da4e-ae3ec4e3be33"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|createtab_stmt                                                                                                                                                 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|CREATE TABLE `desp`.`Despachantes` (\\n  `id` INT,\\n  `nome` STRING,\\n  `status` STRING,\\n  `cidade` STRING,\\n  `vendas` INT,\\n  `data` STRING)\\nUSING parquet\\n|\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Já no caso de Despachantes_ng foi assossiada ao banco de dados DESP, entretanto foi salva num arquivo parquet fora da pasta de gerenciamento automático warehouse do spark (pasta \"spark-warehouse\"), logo, o spark tem controle apenas sobre os metadados da tabela e não sobre seus dados em si. Caso a tabela seja apagada, os dados persistirão no arquito parquet salvo em disco."
      ],
      "metadata": {
        "id": "jS6jZnGunzS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql('show create table Despachantes_ng').show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiW0znJXhgyH",
        "outputId": "3a6eebc5-7897-4027-ab97-4e637de09853"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|createtab_stmt                                                                                                                                                                                                     |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|CREATE TABLE `desp`.`Despachantes_ng` (\\n  `id` INT,\\n  `nome` STRING,\\n  `status` STRING,\\n  `cidade` STRING,\\n  `vendas` INT,\\n  `data` STRING)\\nUSING parquet\\nLOCATION 'file:/content/pyspark_course/dfpqt02'\\n|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Comando que explicita as tabelas e seus respectivos tipos."
      ],
      "metadata": {
        "id": "qzfQ_WnUobkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.catalog.listTables()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzM1frz1h7i7",
        "outputId": "545c67a1-9353-4992-835b-6e84e2a7c77e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='despachantes', database='desp', description=None, tableType='MANAGED', isTemporary=False),\n",
              " Table(name='despachantes_ng', database='desp', description=None, tableType='EXTERNAL', isTemporary=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MHpPQtcfl1y6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}